\documentclass[Journal,SectionNumbers,SingleSpace,InsideFigs]{ascelike}

%\usepackage{subfigure}
%\usepackage{epsfig}
%\usepackage{timesmt}

\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{graphicx}
\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{shapes.misc,fit}

%\usepackage[bookmarks]{hyperref}
\usepackage[colorlinks=true,citecolor=red,linkcolor=black]{hyperref}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}
\newcommand{\posrealszero}{\reals_{\ge 0}}
\newcommand{\naturals}{\mathbb{N}}

\newcommand{\dd}{\,\mathrm{d}}

\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{{\bm#1}}

\newcommand{\uz}{^{(0)}} % upper zero
\newcommand{\un}{^{(n)}} % upper n
\newcommand{\ui}{^{(i)}} % upper i

\newcommand{\ul}[1]{\underline{#1}}
\newcommand{\ol}[1]{\overline{#1}}

\newcommand{\Rsys}{R_\text{sys}}
\newcommand{\lRsys}{\ul{R}_\text{sys}}
\newcommand{\uRsys}{\ol{R}_\text{sys}}

\newcommand{\Fsys}{F_\text{sys}}
\newcommand{\lFsys}{\ul{F}_\text{sys}}
\newcommand{\uFsys}{\ol{F}_\text{sys}}

\def\Rsys{R_\text{sys}}
\def\Tsys{T_\text{sys}}

\newcommand{\E}{\operatorname{E}}
\newcommand{\V}{\operatorname{Var}}
\newcommand{\wei}{\operatorname{Wei}} % Weibull Distribution
\newcommand{\ig}{\operatorname{IG}}   % Inverse Gamma Distribution

\def\yz{y\uz}
\def\yn{y\un}
%\def\yi{y\ui}
\newcommand{\yfun}[1]{y^{({#1})}}
\newcommand{\yfunl}[1]{\ul{y}^{({#1})}}
\newcommand{\yfunu}[1]{\ol{y}^{({#1})}}

\def\ykz{y\uz_k}
\def\ykn{y\un_k}

\def\yzl{\ul{y}\uz}
\def\yzu{\ol{y}\uz}
\def\ynl{\ul{y}\un}
\def\ynu{\ol{y}\un}
\def\yil{\ul{y}\ui}
\def\yiu{\ol{y}\ui}

\def\ykzl{\ul{y}\uz_k}
\def\ykzu{\ol{y}\uz_k}
\def\yknl{\ul{y}\un_k}
\def\yknu{\ol{y}\un_k}


\def\nz{n\uz}
\def\nn{n\un}
%\def\ni{n\ui}
\newcommand{\nfun}[1]{n^{({#1})}}
\newcommand{\nfunl}[1]{\ul{n}^{({#1})}}
\newcommand{\nfunu}[1]{\ol{n}^{({#1})}}

\def\nkz{n\uz_k}
\def\nkn{n\un_k}
\newcommand{\nkzfun}[1]{n\uz_{#1}}
\newcommand{\nkzlfun}[1]{\ul{n}\uz_{#1}}
\newcommand{\nkzufun}[1]{\ol{n}\uz_{#1}}

\def\nzl{\ul{n}\uz}
\def\nzu{\ol{n}\uz}
\def\nnl{\ul{n}\un}
\def\nnu{\ol{n}\un}
\def\nil{\ul{n}\ui}
\def\niu{\ol{n}\ui}

\def\nkzl{\ul{n}\uz_k}
\def\nkzu{\ol{n}\uz_k}
\def\nknl{\ul{n}\un_k}
\def\nknu{\ol{n}\un_k}


\def\taut{\tau(\vec{t})}
\def\ttau{\tilde{\tau}}
\def\ttaut{\ttau(\vec{t})}

\def\MZ{\mathcal{M}\uz}
\def\MN{\mathcal{M}\un}

\def\MkZ{\mathcal{M}\uz_k}
\def\MkN{\mathcal{M}\un_k}

\def\PkZ{\Pi\uz_k}
\def\PkN{\Pi\un_k}
\newcommand{\PZi}[1]{\Pi\uz_{#1}}


\def\tnow{t_\text{now}}
\def\tpnow{t^+_\text{now}}

\newcommand{\comments}[1]{{\small\color{gray} #1}}

\newtheorem{example}{Example}

\allowdisplaybreaks

\title{Notes for ISIPTA poster}
\author{Gero Walter, Frank P.A. Coolen, Simme Douwe Flapper}

\begin{document}
\title{ROBUST BAYESIAN RELIABILITY FOR COMPLEX SYSTEMS\\ or \ldots}

\author{
Gero Walter%
\thanks{
School of Industrial Engineering,
Eindhoven University of Technology, Eindhoven, The Netherlands.
E-mail: g.walter@tue.nl.},
\ Ph.D.
\\
and
Frank P.A. Coolen%
\thanks{
Department of Mathematical Sciences,
Durham University, Durham, United Kingdom.
E-mail: frank.coolen@durham.ac.uk.},
\ Ph.D.
\\
and ???
}

\maketitle

Invited for special issue ``The treatment of uncertainty in risk and reliability modelling and decision making''
(special issue code SI022A), guest editors Luca Podolfillini, Bruno Sudret, Enrico Zio,
in ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems: Part A (Civil Engineering)

***``For most ASCE journals, the maximum number of words and word-equivalents is 10,000 for technical papers''

***Abstract must be 150--175 words long (this has 175), may not contain references or mathematics.

\begin{abstract}
In reliability engineering, data about failure events is often scarce.
To arrive at meaningful estimates for the reliability of a system,
it is therefore often necessary to also include expert information in the analysis,
which is straightforward in the Bayesian approach by using an informative prior distribution.
%
A problem called prior-data conflict then can arise:
observed data seem very surprising from the viewpoint of the prior,
i.e., information from data is in conflict with prior assumptions.
Models based on conjugate priors can be insensitive to prior-data conflict,
in the sense that the spread of the posterior distribution does not increase in case of such a conflict,
thus conveying a false sense of certainty.
%
We present an approach to mitigate this issue, by considering sets of prior distributions
to model limited knowledge on Weibull distributed component lifetimes,
treating systems with arbitary layout using the survival signature.
Our approach can be seen as a robust Bayesian procedure or imprecise probability method
that reflects surprisingly early or late component failures
by wider system reliability bounds.
%We show how surprisingly early or late component failures
%result in wider system reliability bounds.
%
%and study how surprisingly early or late component failures
%affect the prediction of the reliability of a system with arbitrary layout,
%making use of survival signature to characterise the system under study.
%Our approach can be seen as a robust Bayesian procedure or imprecise probability method
%that appropriately reflects surprising data in the posterior system reliability function.
\end{abstract}
% by communicating that we can quantify the reliability of a system quite precisely when in fact we cannot.

\KeyWords{System Reliability, Imprecise Probability, Survival Signature, Robust Bayesian Methods, Remaining Useful Life}


\section{Introduction}

In reliability engineering, a central task is to describe the reliability of a complex system.
This is usually done by determining the \emph{reliability function} $R(t)$,
in other contexts also known as the \emph{survival function} $S(t)$,
giving the probability that the system has not failed by time $t$:
\begin{align}
\Rsys(t) = P(\Tsys \geq t)\,,
\end{align}
where $\Tsys$ is the random variable giving the failure time of the system. %
%\footnote{}
Based on the distribution of $\Tsys$, which can also be expressed
in terms of the cumulative distribution function $F_\text{sys}(t) = 1 - \Rsys(t)$,
%the density $p_\text{sys}(t)$ or the hazard rate $\lambda_\text{sys}(t)$,
decisions about, e.g., scheduling of maintenance work can be made.

Often, there is no failure data for the system itself
(e.g., if the system is a prototype, or the system is used under unique circumstances),
but there is some information about failure times for the components the system is made of.
We are able to analyse systems of arbitrary system structures, %layout of components,
i.e., any combination and nesting of series, parallel, k-out-of-n, or bridge-type arrangements,
by use of the survival signature \cite{2012:survsign}.
In this paper, we assume that components can be divided into $K$ different groups,
and components within each group $k$ ($k=1, \ldots, K$) can be assumed to be exchangeable,
i.e., to follow the same failure time distribution.
We denote components of group $k$ as \emph{type $k$ components},
and assume independence between component types,
such that failure times of components of different types are independent.
We assume that type $k$ component lifetimes $T_i^k$ ($i = 1, \ldots, n_k$)
are Weibull distributed, with type-specific parameters $\beta_k$ (shape) and $\lambda_k$ (scale).
***type-specific shape not implemented yet!***

Focusing on the prototype application,
we assume that our observations consist solely of the failure times of components in this system up to time $\tnow$,
such that the failure times of components that have not failed by $\tnow$ are right-censored,
and calculate $\Rsys(t \mid t > \tnow) = P(\Tsys \geq t \mid t > \tnow)$,
which can be used to determine the remaining useful life of the system
(in short RUL, see, e.g., \citeNP{2014:rul-review}).
%This sparse information is complemented by expert information on component lifetimes $T_i^k$.

The Bayesian approach allows to base estimation of the component failure distributions
on both data and further knowledge not given by the data,
the latter usually provided in the form of expert knowledge.
This knowledge is encoded in form of a so-called prior distribution,
a distribution on the parameters of the component lifetime distributions.
Expert knowledge is especially important when there is very few data on the components (like in our scenario),
as only with its help meaningful estimates for the system reliability can be made.

However, the choice for the prior distribution to encode the given expert knowledge is often debatable,
and a specific choice of prior is difficult to justify.
A way to deal with this is to employ sensitivity analysis,
i.e., studying the effect of different choices of prior distribution on the quantities of interest
(in our case, the system reliability function, which, in Bayesian terms, is a predictive distribution).
This idea has been explored in systematic sensitivity analysis, or robust Bayesian methods
(for an overview on this approach, see, e.g.,
\citeNP{1994:berger} or \citeNP{2000:rios}). %\citeNP{2005:ruggeri}, \citeNP{2000:bergerinsuaruggeri}

The work we present here can be seen as belonging to the robust Bayesian approach,
as our work uses sets of priors. However, our focus and interpretation is slightly different,
as we consider the result of our procedure, sets of reliability functions, as the proper result,
while a robust Bayesian would base his analyses on a single reliability function from the set
in case (s)he was able to conclude that quantities of interest are not `too sensitive' to the choice of prior.
In contrast, our viewpoint is rooted in the theory of imprecise or interval probability \cite{1991:walley,itip},
where sets of distributions are used to express the precision of probability statements themselves:
the smaller the set, the more precise the probability statement.
Indeed, the system reliability function $\Rsys(t)$ is a collection of probability statements,
and a small set for $\Rsys(t)$ will indicate that we can quantify the reliability of the system quite precisely,
while a large set will indicate that our knowledge about $\Tsys$ is rather shaky.

In line with imprecise or interval probability methods, we will thus have, for each $t$,
a lower reliability $\lRsys(t) = \ul{P}(T_\text{sys} \geq t)$,
and an upper reliability $\uRsys(t) = \ol{P}(T_\text{sys} \geq t)$.
We will explain in Sections~\ref{sec:modforsurpr} and *** how these bounds are obtained
based on a set of prior distributions on the scale parameter of the component lifetime distribution.

The central merit of our method is that it adequately reflects prior-data conflict
(see, e.g., \citeNP{2006:evans}),
i.e.\ the conflict that can arise between prior assumptions on component lifetimes
and observed behaviour of components in the system under study.
As we will show in Section~\ref{sec:weibull}, when taking the standard choice of a conjugate prior,
prior-data conflict is ignored, as the spread of the posterior distribution does not increase in case of such a conflict,
ultimately conveying a false sense of certainty
by communicating that we can quantify the reliability of a system quite precisely when in fact we can not.
%
In contrast, our method will indicate prior-data conflict by wider bounds for $\Rsys(t)$.
This behaviour is obtained by a specific choice for the set of priors (see \citeNP{Walter2009a} and \citeNP{diss} \S 3.1.4)
which leads to larger sets of posterior distributions when prior knowledge and data are in conflict
(see Section~\ref{sec:modforsurpr} for more details).

Due to the iterative nature of the Bayesian framework,
it is possible to use a set of posteriors based on component test data as the set of priors
instead of a purely expert-based set of priors as discussed so far.
In that case, prior-data conflict sensitivity allows to uncover also a conflict between
current observations in the running system and past observations from component tests.

This work extends \ldots ***

***comment on shape parameter $\beta_k$ being fixed***

We study the effect of surprisingly early or late component failures,
%on the system reliability prediction,
showing that observations in conflict to prior assumptions
indeed lead to more cautious system reliability predictions.

  
The paper is organized as follows.
In Section~\ref{sec:weibull}, we describe a Bayesian analysis for Weibull component lifetimes
and illustrate the issue of prior-data conflict.
Section~\ref{sec:modforsurpr} then details the use of sets of priors
for the scale parameter $\lambda_k$ of the Weibull distribution,
showing how this mitigates the prior-data conflict issue for $\lambda_k$.
***

%In the last section, we will briefly describe
%how the approach can be generalized to arbitrary system structures
%using the survival signature \cite{2012:survsign},
%which allows for different types of components and
%the inclusion of data from component tests, as in \citeNP{2014:bayessurvsign}.
%Information on the distribution of component failure times $T_i$,
%where $i = 1, \ldots, n$ if the system consists of $n$ components,
%can then be used to derive the distribution of $T_\text{sys}$.


\section{Bayesian Analysis of Weibull Lifetimes}
\label{sec:weibull}

We consider a system with components of $k=1,\ldots,K$ different types;
for each type $k$, there are $n_k$ exchangeable components in the system.
For each type $k$ component, we assume for its lifetime $T_i^k$ ($i=1,\ldots,n_k$, $k = 1, \ldots, K$)
a Weibull distribution with fixed shape parameter $\beta_k > 0$,
in short $T_i^k \mid \lambda_k \sim \wei(\beta_k,\lambda_k)$,
with density and cdf%
\footnote{Our approach would be possible also for other parametric lifetime distributions
that form a canonical exponential family
(see, e.g., \citeNP[p.~202 and 272f]{2000:bernardosmith}, or \citeNP[p.~8]{diss}).}
\begin{linenomath*}
\begin{align}
\label{eq:weibulldens}
f(t_i^k \mid \lambda_k) &= \frac{\beta_k}{\lambda_k} (t_i^k)^{\beta_k-1} e^{-\frac{(t_i^k)^{\beta_k-1}}{\lambda_k}}\,, \\
\label{eq:weibullcdf}
F(t_i^k \mid \lambda_k) &= 1 - e^{-\frac{(t_i^k)^{\beta_k}}{\lambda_k}} = P(T_i^k \leq t_i^k \mid \lambda_k)\,,
\end{align}
\end{linenomath*}
where $\lambda_k > 0$ and $t > 0$.%
\footnote{The shape parameter $\beta_k$ determines whether the hazard rate is increasing ($\beta_k > 1$)
or decreasing ($\beta_k < 1$) over time.
For $\beta_k=1$, we obtain the Exponential distribution with constant hazard rate as a special case.
The value for $\beta_k$ will thus often be clear from practical considerations.}
The scale parameter $\lambda_k$ can be interpreted through the relation
\begin{linenomath*}
\begin{align}
\E[T_i^k \mid \lambda_k] &= \lambda_k^{1/\beta_k}\, \Gamma(1 + 1/\beta_k)\,.
\label{eq:lambdainterpret}
\end{align}
\end{linenomath*}
For encoding expert knowledge about the reliability of the components,
we need to assign a prior distribution over the scale parameter $\lambda_k$.
A convenient choice is to use the inverse Gamma distribution,
commonly parametrized in terms of the hyperparameters $a_k > 0$ and $b_k > 0$:
%Conjugate prior is $\lambda_k \sim \ig(a_k,b_k)$:
\begin{linenomath*}
\begin{align}
f(\lambda_k\mid a_k,b_k) &= \frac{(b_k)^{a_k}}{\Gamma(a_k)} \lambda_k^{-a_k -1} e^{-\frac{b_k}{\lambda_k}}
\label{eq:ig-def}
\end{align}
\end{linenomath*}
in short, $\lambda_k \mid a_k, b_k \sim \ig(a_k,b_k)$.
The inverse Gamma is convenient because it is a conjugate prior,
i.e., the posterior obtained by Bayes' rule is again inverse Gamma and thus easily tractable;
the prior parameters only need to be updated to obtain the posterior parameters.

In the standard Bayesian approach, 
one has to fix a prior by choosing values for $a_k$ and $b_k$
to encode specific prior information about component lifetimes.
In our imprecise approach, we allow instead these parameters
to vary in a set, this is advantageous also
because expert knowledge is often vague,
and it is difficult for the expert(s) to pin down precise hyperparameter values.
For the definition of the hyperparameter set,
we use however a parametrization in terms of $\nz > 1$ and $\yz > 0$ instead of $a_k$ and $b_k$,
where we drop the index $k$ for the discussion about the prior model in the following,
keeping in mind that each component type will have its own specific parameters.
We use
%\begin{linenomath*}
%\begin{align}
$\nz = a - 1$ and
%&
$\yz = b / \nz$,
%\end{align}
%\end{linenomath*}
where $\yz$ can be interpreted as the prior guess for the scale parameter $\lambda$,
as $\E[\lambda\mid\nz,\yz] = \yz$.
This parametrization also makes the nature of the combination
of prior information and data through Bayes' rule more clear:
After observing $n$ component lifetimes $\vec{t} = (t_1, \ldots, t_n)$,
the updated parameters are
\begin{linenomath*}
\begin{align}
\nn &= \nz + n\,, 
&
\yn &=  \frac{\nz \yz + \taut}{\nz + n}\,,
\label{eq:ig-update}
\end{align}
\end{linenomath*}
where $\taut = \sum_{i=1}^n (t_i)^\beta$. %
%\footnote{
We thus have
\begin{linenomath*}
\begin{align}
\lambda \mid \nz, \yz, \vec{t} \sim \ig(\nz + n + 1, \nz \yz + \taut). %}
\label{eq:ig-update-alpha}
\end{align}
\end{linenomath*}
%In terms of canonical parameters $\nkz$ and $\ykz$, we assume $\lambda_k \mid \nkz,\ykz \sim \ig(\nkz + 1, \nkz\ykz)$.
From the simple update rule \eqref{eq:ig-update}, we see that
$\yn$ is a weighted average of the prior parameter $\yz$ and the maximum likelihood (ML) estimator $\taut/n$,
with weights $\nz$ and $n$, respectively.
$\nz$ can thus be interpreted as a prior strength or pseudocount,
indicating how much our prior guess should weigh against the $n$ observations.
Furthermore, $\V[\lambda\mid\nz,\yz] = (\yz)^2 / (1 - 1/\nz)$,
so for fixed $\yz$, the higher $\nz$,
the more probability mass is concentrated around $\yz$. %$p(\lambda\mid\nz,\yz)$ 

However, the weighted average structure for $\yn$
is behind the problematic behaviour in case of prior-data conflict.
Assume that from expert knowledge we expect
to have a mean component lifetime of 9 weeks.
Using \eqref{eq:lambdainterpret}, with $\beta=2$ we obtain $\yz = 103.13$.
We choose $\nz = 2$, so our prior guess for the mean component lifetime
counts like having two observations with this mean.
If we now have a sample of two observations
with surprisingly early failure times $t_1 = 1$ and $t_2 = 2$,
using \eqref{eq:ig-update} we get $\nfun{2} = 4$
and $\yfun{2} = \frac{1}{4}(2 \cdot 103.13 + 1^2 + 2^2) = 52.82$,
so our posterior expectation for the scale parameter $\lambda$ is $52.82$,
equivalent to a mean component lifetime of $6.44$ weeks.
The posterior standard deviation (sd) for $\lambda$ is $60.99$.
Compared to the prior standard deviation of $145.85$,
the posterior expresses now more confidence that mean lifetimes are around $\yfun{2} = 52.82$
than the prior had about $\yz = 103.13$.
This irritating conclusion is illustrated in Figure~\ref{fig:weibull-pdc};
the posterior cdf is shifted halfway towards the values for $\lambda$
that the two observations suggest
(the ML estimator for $\lambda$ would be $2.5$),
and is steeper than the prior (so the pdf is more pointed),
thus conveying a false sense of certainty about $\lambda$.%
\footnote{This is a general problem in Bayesian analysis with canonical conjugate priors.
For such priors, the same update formula \eqref{eq:ig-update} applies,
and so conflict is averaged out, for details see \citeN{Walter2009a} and \citeN[\S 3.1.4 and \S A.1.2]{diss}.}
We would obtain almost the same %values of $\nfun{2}$ and $\yfun{2}$, and so the same 
posterior distribution
if we had assumed the mean component lifetime to be 7 weeks (so $\yz = 62.39$),
and observed lifetimes $t_1 = 6$, $t_2 = 7$ in line with our expectations.
It seems unreasonable to make the same probability statements on component lifetimes in these two fundamentally different scenarios.
%
%\iffalse
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{fig1}
\caption{Prior and posterior cdf for $\lambda$ given surprising observations;
the conflict between prior assumptions and data is averaged out,
with a more pointed posterior giving a false sense of certainty.}
\label{fig:weibull-pdc}
\end{figure}
%\fi


\section{Models reflecting surprising data / Sets of Priors}
\label{sec:modforsurpr}

Despite this issue of ignoring prior-data conflict,
the tractability of the update step
(the posterior is again a parametric distribution)
is a very attractive feature of the conjugate setting.
As was shown by \citeN{Walter2009a} (see also \citeNP{diss}, \S 3.1),
it is possible to retain tractability and to have a meaningful reaction to prior-data conflict
when using sets of priors generated by varying both $\nz$ and $\yz$.
Then, the magnitude of the set of posteriors,
and with it the precision of posterior probability statements,
will be sensitive to the degree of prior-data conflict,
i.e.\ leading to more cautious probability statements when prior-data conflict occurs.

Instead of a single prior guess $\yz$ for the mean component lifetimes,
we will now assume a range of prior guesses $[\yzl, \yzu]$, and also a range $[\nzl, \nzu]$ of pseudocounts,
i.e., we now consider the set of priors
\begin{linenomath*}
\begin{align}
\MZ := \{ f(\lambda\mid\nz,\yz) \mid \nz \in [\nzl, \nzu], \yz \in [\yzl, \yzu] \}
\label{eq:setofpriors}
\end{align}
\end{linenomath*}
to express our prior knowledge about component lifetimes.
Each of the priors $f(\lambda\mid\nz,\yz)$ is then updated to the posterior
$f(\lambda\mid\nz,\yz,\vec{t}) = f(\lambda\mid\nn,\yn)$
by using \eqref{eq:ig-update},
such that the set of posteriors $\MN$ can be written as
$\MN = \{ f(\lambda\mid\nn,\yn) \mid \nz \in [\nzl, \nzu], \yz \in [\yzl, \yzu] \}$.
This procedure of using Bayes' Rule element by element
is seen as self-evident in the robust Bayesian literature,
but can be formally justified as being \emph{coherent}
(a self-consistency property)
in the framework of imprecise probability, where it is known as
\emph{Generalized Bayes' Rule} \cite[\S 6.4]{1991:walley}.

Technically, it is crucial to consider a range of pseudocounts $[\nzl, \nzu]$
along with the range of prior guesses $[\yzl, \yzu]$,
as only then $\taut/n \not\in [\yzl, \yzu]$
leads to the set of posteriors being larger
and hence reflecting prior-data conflict.

Continuing the example from Section~\ref{sec:weibull} and Figure~\ref{fig:weibull-pdc},
assume now for the mean component lifetimes the range 9 to 11 weeks,
this corresponds to $[\yzl,\yzu] = [103.13, 154.06]$.
We also choose $[\nzl,\nzu] =[2, 5]$,
so we value our prior information as equivalent to having seen two to five observations.
Compare now the set of posteriors obtained from observing
$t_1 = 1$, $t_2 = 2$ (as before), see Figure~\ref{fig:setofpost-pdc-nopdc} (left),
and $t_1 = 10$, $t_2 = 11$, see Figure~\ref{fig:setofpost-pdc-nopdc} (right).
We now have a clear difference between the two scenarios of
observations in line with expectations and observations in conflict.
In the prior-data conflict case, the set of posteriors (blue)
is shifted towards the left, but has about the same size as the set of priors (yellow),
and so posterior quantification of reliability has the same precision,
despite having seen two observations.
Instead, in the no conflict case, the set of posteriors is smaller than the set of priors,
such that the two observations have increased the precision of reliability statements.

\begin{figure}
\includegraphics[width=\textwidth]{fig2}
\caption{Set of prior and posterior cdfs for $\lambda$ for two surprising observations $t_1 = 1$, $t_2 = 2$ (left)
and two unsurprising observations $t_1 = 10$, $t_2 = 11$ (right).}
\label{fig:setofpost-pdc-nopdc}
\end{figure}

As each posterior in $\MN$ corresponds to a predictive distribution for $\Tsys$,
we will have a set of reliability functions $\Rsys(t)$.
The derivation of $\Rsys(t)$ for systems with $K$ component types and arbitrary layout
will be given in Section~\ref{sec:robrel} below.
This will include, in contrast to previous studies using sets of priors of type 
\eqref{eq:setofpriors}, the treatment of censored observations.
More specifically, we consider the case of \emph{non-informative right censoring},
where the censoring process is independent of the failure process.


\section{Robust Reliability for Complex Systems via the Survival Signature}
\label{sec:robrel}

We now consider a system of arbitrary layout,
consisting of components of $K$ types.
This system is observed until time $\tnow$,
leading to censored observation of lifetimes of components within the system,
and we will explain in Section~\ref{sec:lambdawithcens}
how the scale parameter $\lambda_k$ for component type $k$
can be estimated in this situation.
%
Section~\ref{sec:sysrelwithsurvsign} describes then
how the system reliability function can be efficiently obtained using the survival signature.
%
For this, we need the posterior predictive distribution
of the number of components function at times $t > \tnow$,
which we will derive in Section~\ref{sec:postpred}.
%
Finally, in Section~\ref{sec:optimize} we describe how
the lower and upper bound for the system reliability function
are obtained when prior parameters $(\nkz,\ykz)$
vary in sets $\PkZ = [\nkzl,\nkzu] \times [\ykzl,\ykzu]$,
defining sets $\MkZ$ of prior distributions over $\lambda_k$,
as introduced in Section~\ref{sec:modforsurpr}.


\subsection{Bayesian Estimation of Component Scale Parameter with Right-censored Lifetimes}
\label{sec:lambdawithcens}

Consider observing a prototype system until $\tnow$,
where the system has $K$ different types of components,
and for each type $k$ there are $n_k$ components in the system.
Denoting the number of type $k$ components that have failed by $\tnow$ by $e_k$,
there are $n_k - e_k$ components still functioning at $\tnow$.
We denote the corresponding vector of observations by
\begin{linenomath*}
\begin{align}
\vec{t}^k_{e_k;n_k} &= \big( \underbrace{t^k_1, \ldots, t^k_{e_k}}_{e_k \text{failure times}},
                             \underbrace{\tpnow, \ldots, \tpnow}_{n_k-e_k \text{censored obs.}} \big)\,,
\end{align}
\end{linenomath*}
where $t^+$ indicates a right-censored observation.
%
%***change to general right-censoring? So $n_k-e_k \to c_k$, $e_k+c_k=n_k$,
%introduce sets of observed and censored?

According to Bayes' rule, multiplying the prior density and the likelihood
(which accounts for right-censored observations through the cdf terms)
gives a term proportional to the density of the posterior distribution for $\lambda_k$:
\begin{linenomath*}
\begin{align}
%f_{\lambda_k\mid\ldots}(\lambda_k\mid\nkz,\ykz,\mbf{t}^k_{e_k;n_k})
% &\propto f_{\lambda_k}(\lambda_k)
%          \big[ 1- F_k(\tnow\mid\lambda_k) \big]^{n_k-e_k}
%          \prod_{i=1}^{e_k} f_k(t_i^k \mid \lambda_k) 
f(\lambda_k\mid\nkz,\ykz,\vec{t}^k_{e_k;n_k})
 &\propto f(\lambda_k)
          \big[ 1- F(\tnow\mid\lambda_k) \big]^{n_k-e_k}
          \prod_{i=1}^{e_k} f(t_i^k \mid \lambda_k) 
\end{align}
\end{linenomath*}
Conjugacy is preserved and we get 
$\lambda_k\mid\nkz,\ykz,\vec{t}^k_{e_k;n_k} \sim \ig(\nkn + 1, \nkn\ykn)$, where
\begin{linenomath*}
\begin{align}
\nkn + 1 &= \nkz + e_k + 1 \\
\nkn\ykn &= \nkz\ykz + (n_k-e_k) (\tnow)^\beta + \sum_{i=1}^{e_k} (t_i^k)^\beta
\end{align}
\end{linenomath*}
are the updated parameters of the inverse gamma distribution.
%The posterior expectation for $\lambda_k$ is
%\begin{linenomath*}
%\begin{align}
%\E[\lambda_k\mid\nkn,\ykn] &= \ykn
%                            = \frac{\nkz}{\nkz + e_k} \ykz +
%                              \frac{e_k}{\nkz + e_k} \cdot \Big[\frac{n_k-e_k}{e_k} (\tnow)^\beta 
%                                                                    + \frac{1}{e_k} \sum_{i=1}^{e_k} (t_i^k)^\beta \Big]
%\end{align}
%\end{linenomath*}


\subsection{System Reliability using the Survival Signature}
\label{sec:sysrelwithsurvsign}

The structure of complex systems can be visualized by reliability block diagrams,
an example is given in Figure~\ref{fig:bridge-layout}.
Components are represented by boxes or nodes,
and the system works when a path from the left end to the right exists
which passes only through working components.
In a system with $n$ components, the state of the components can be expressed by the state vector
$\vec{x} = (x_1,x_2,\ldots,x_n) \in \{0,1\}^n$, with $x_i=1$ if the $i$th component functions 
and $x_i=0$ if not.
The structure function $\phi : \{0,1\}^n \rightarrow \{0,1\}$, defined for all possible $\vec{x}$, takes 
the value 1 if the system functions and 0 if the system does not function for state vector $\vec{x}$
\cite{BP75}.
Most real-life systems are coherent,
which means that $\phi(\vec{x})$ is non-decreasing in any of the components of $\vec{x}$,
so system functioning cannot be improved by worse performance of one or more of its components.
Furthermore, one can usually assume that $\phi(0, \ldots, 0) = 0$ and $\phi(1, \ldots, 1) = 1$.

The survival signature \cite{2012:survsign} is a summary of the structure function
for systems with $K$ groups of exchangeable components.
Denoted by $\Phi(l_1,\ldots,l_K)$, with $l_k=0,1,\ldots,n_k$ for $k=1,\ldots,K$,
it is defined as the probability for the event that the system functions
given that precisely $l_k$ of its $n_k$ components of type $k$ function, for each $k\in \{1,\ldots,K\}$.
Essentially, this creates a $K$-dimensional partition for the event $\Tsys > t$,
such that $\Rsys(t) = P(\Tsys > t)$ can be calculated using the law of total probability,
%System survival calculated by %(see Risk Analysis paper eq. (7))
\begin{linenomath*}
\begin{align}
P(\Tsys > t) &= \sum_{l_1=0}^{m_1} \cdots \sum_{l_K=0}^{m_K} P(\Tsys > t \mid C^1_t = l_1,\ldots, C^K_t = l_K)
                                                                                  P\Big( \bigcap_{k=1}^K \{ C^k_t = l_k\} \Big) \nonumber\\
             &= \sum_{l_1=0}^{n_1} \cdots \sum_{l_K=0}^{n_K} \Phi(l_1,\ldots,l_K) P\Big( \bigcap_{k=1}^K \{ C^k_t = l_k\} \Big) \nonumber\\
%\intertext{ and assuming components of different types are independent,}
             &= \sum_{l_1=0}^{n_1} \cdots \sum_{l_K=0}^{n_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K P(C^k_t = l_k)\,,
\label{eq:sysrel-survsign}
\end{align}
\end{linenomath*}
where $P(C^k_t = l_k)$ is the (predictive) probability that exactly $l_k$ components of type $k$ function at time $t$,
and the last equality holds as we assume that components of different types are independent.
Note that for coherent systems,
the survival signature $\Phi(l_1,\ldots,l_K)$ is non-decreasing in each $l_k$.
%
%A priori, we have, for $l_k = 0,1,\ldots, n_k$,
%\begin{linenomath*}
%\begin{align}
%P(C^k_t = l_k\mid\nkz,\ykz)
% &= { n_k \choose l_k} \int [F_k(t \mid\lambda_k)]^{n_k-l_k}
%                        [1 - F_k(t \mid\lambda_k)]^{l_k} f_{\lambda_k}(\lambda_k\mid\nkz,\ykz) \dd \lambda_k
%\end{align}
%\end{linenomath*}
%under the assumption that components of the same type are independent given $\lambda_k$.


\subsection{Posterior Predictive Distribution}
\label{sec:postpred}

In calculating the system reliability using \eqref{eq:sysrel-survsign},
the component-specific predictive probabilities $P(C^k_t = l_k)$
need to use all information available at time $\tnow$,
which, in the Bayesian framework,
are given by the posterior predictive distribution 
$P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})$, $l_k = 0, 1, \ldots, n_k-e_k$. %$k=1,\ldots, K$.
(Remember that $e_k$ type $k$ components have failed by $\tnow$,
such that there can be at most $n_k-e_k$ working components beyond time $\tnow$.)
%(Should one work with the subsystem consisting only of the non-failed $n_k - e_k$ components?)\\
This posterior predictive distribution is obtained as
\begin{linenomath*}
\begin{align}
\lefteqn{%
P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})}\hspace*{5ex} \nonumber\\  %
 &= { n_k - e_k \choose l_k} \int \big[P(T^k >    t \mid T^k > \tnow, \lambda_k)\big]^{l_k} \times \nonumber\\ & \hspace*{17ex}
                                  \big[P(T^k \leq t \mid T^k > \tnow, \lambda_k)\big]^{n_k - e_k - l_k}
    f(\lambda_k\mid\nkz,\ykz,\vec{t}^k_{e_k;n_k}) \dd \lambda_k
\label{eq:postpredtnow}
\end{align}
\end{linenomath*}
%
Now, by the Weibull assumption \eqref{eq:weibullcdf}, we have
\begin{linenomath*}
\begin{align}
P(T^k \leq t \mid T^k > \tnow, \lambda_k)
 &= \frac{P(\tnow < T^k \leq t \mid\lambda_k)}{P(T^k > \tnow \mid \lambda_k)} \nonumber\\
 &= \frac{F(t\mid\lambda_k) - F(\tnow\mid\lambda_k)}{1-F(\tnow\mid\lambda_k)} 
% = \frac{e^{-\frac{(\tnow)^{\beta_k}}{\lambda_k}} - e^{-\frac{t^{\beta_k}}{\lambda_k}}}{e^{-\frac{(\tnow)^{\beta_k}}{\lambda_k}}}
  = 1 - e^{-\frac{t^{\beta_k} - (\tnow)^{\beta_k}}{\lambda_k}}\,.
\end{align}
\end{linenomath*}
%
With this and the posterior \eqref{eq:ig-update-alpha} substituted into \eqref{eq:postpredtnow}, we get
\begin{linenomath*}
\begin{align}
\lefteqn{P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})}\hspace*{5ex} \nonumber\\
 &= { n_k - e_k \choose l_k} \int \Big[    e^{-\frac{t^{\beta_k} - (\tnow)^{\beta_k}}{\lambda_k}}\Big]^{l_k}
                                  \Big[1 - e^{-\frac{t^{\beta_k} - (\tnow)^{\beta_k}}{\lambda_k}}\Big]^{n_k - e_k - l_k}
    \times \nonumber\\ & \hspace*{27ex}
    \frac{\big(\nkn\ykn\big)^{\nkn + 1}}{\Gamma(\nkn+1)} \lambda_k^{-(\nkn + 1) - 1} e^{-\frac{\nkn\ykn}{\lambda_k}} \dd \lambda_k \nonumber\\
 &= { n_k - e_k \choose l_k} \sum_{j=0}^{n_k-e_k-l_k} (-1)^j { n_k - e_k - l_k \choose j} \frac{\big(\nkn\ykn\big)^{\nkn + 1}}{\Gamma(\nkn+1)} 
    \times \nonumber\\ & \hspace*{13ex}
    \int \lambda_k^{-(\nkn + 1) - 1} \exp\Big\{-\frac{(l_k + j) (t^{\beta_k} - (\tnow)^{\beta_k}) + \nkn\ykn}{\lambda_k}\Big\} \dd \lambda_k\,.
\end{align}
\end{linenomath*}
%
The terms remaining under the integral form the core of an inverse gamma distribution \eqref{eq:ig-def}
with parameters $\nkn + 1$ and $\nkn\ykn + (l_k + j) (t^{\beta_k} - (\tnow)^{\beta_k}))$,
allowing us to solve the integral using the corresponding normalization constant.
We thus have, for $l_k \in \{0,1,\ldots,n_k-e_k\}$,
\begin{linenomath*}
\begin{align}
\lefteqn{P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})} \nonumber\\
 &= { n_k - e_k \choose l_k} \sum_{j=0}^{n_k-e_k-l_k} (-1)^j { n_k - e_k - l_k \choose j}
    \left(\frac{\nkn\ykn}{\nkn\ykn + (l_k + j) \big(t^{\beta_k} - (\tnow)^{\beta_k}\big)}\right)^{\nkn + 1} \nonumber\\
 &= \sum_{j=0}^{n_k-e_k-l_k} (-1)^j \frac{(n_k - e_k)!}{l_k! j! (n_k - e_k - l_k - j)!}   
    \left(\frac{\nkn\ykn}{\nkn\ykn + (l_k + j) \big(t^{\beta_k} - (\tnow)^{\beta_k}\big)}\right)^{\nkn + 1} \nonumber\\
 &= \sum_{j=0}^{n_k-e_k-l_k} (-1)^j \frac{(n_k - e_k)!}{l_k! j! (n_k - e_k - l_k - j)!} \times \nonumber\\ & \hspace*{10ex}  
    \left(\frac{\nkz\ykz + \sum_{i=1}^{e_k} (t_i^k)^{\beta_k} + (n_k-e_k)       (\tnow)^{\beta_k} }%
               {\nkz\ykz + \sum_{i=1}^{e_k} (t_i^k)^{\beta_k} + (n_k-e_k-l_k-j) (\tnow)^{\beta_k} + (l_k + j) t^{\beta_k} }\right)^{%
    \nkz + e_k + 1}.
\label{eq:postpred-priorparams}
\end{align}
\end{linenomath*}
%
These posterior predictive probabilities can also be expressed as a cumulative probability mass function (cmf) 
\begin{linenomath*}
\begin{align}
F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k}) = P(C^k_t \leq l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k}) 
 = \sum_{j=0}^{l_k} P(C^k_t = j \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})\,.
%F_{C^k_t}(l_k \mid \ldots) = P(C^k_t \leq l_k\mid\ldots) = \sum_{q=0}^{l_k} P(C^k_t = q\mid\ldots)\,,
\end{align}
\end{linenomath*}
%Seen as function in $t$, we see that $t$ appears $n_k-e_k-l_k+1$ times,
%once in each summand, in the denominator of the fraction powered to the $\nkn+1$,
%and summands whith even $j$ are decreasing in $t$,
%while summands whith odd $j$ are increasing in $t$.
%Nevertheless, in total $P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})$
%must be decreasing in $t$, as the remaining $n_k-e_k$ components continue to age,
%and so the probability that $l_k$ of them remain operational must decrease.


\subsection{Optimizing over Sets of Parameters}
\label{sec:optimize}

Together with \eqref{eq:postpred-priorparams},
\eqref{eq:sysrel-survsign} allows us to calculate the system reliability $\Rsys(t\mid t>\tnow)$
for fixed prior parameters $(\nkz, \ykz)$, $k=1, \ldots, K$.
In Section~\ref{sec:modforsurpr}, we argued for using sets of priors $\MZ$,
which allow for vague and incomplete prior knowledge, and provide prior-data conflict sensitivity.
%
We will thus use, for each component type,
a set of priors $\MkZ$ defined by varying $(\nkz,\ykz)$ in a prior parameter set $\PkZ = [\nkzl,\nkzu] \times [\ykzl,\ykzu]$,
and we are interested in the bounds
%This leads to a set of system reliability functions with the bounds
\begin{linenomath*}
\begin{align}
\lRsys(t \mid t > \tnow) &= \min_{\PZi{1},\ldots,\PZi{K}} \Rsys\big(t \mid t > \tnow, \cup_{k=1}^K \{\PkZ, \vec{t}^k_{e_k;n_k}\}\big)\,,
\label{eq:lrsysdef}\\
\uRsys(t \mid t > \tnow) &= \max_{\PZi{1},\ldots,\PZi{K}} \Rsys\big(t \mid t > \tnow, \cup_{k=1}^K \{\PkZ, \vec{t}^k_{e_k;n_k}\}\big)\,,
\label{eq:ursysdef}
\end{align}
\end{linenomath*}
where we surpress in notation that $\lRsys(t \mid t > \tnow)$ and $\uRsys(t \mid t > \tnow)$
depend on prior parameter sets and data.

\eqref{eq:lrsysdef} and \eqref{eq:ursysdef} seem to suggest that
a full $2K$-dimensional box-constraint optimization is necessary,
but this is not the case.
Remember that $\Phi(l_1,\ldots,l_k)$ from \eqref{eq:sysrel-survsign} is non-decreasing in each of its arguments $l_1,\ldots,l_K$,
so if there is stochastic dominance in $F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$,
then there is, for each component type $k$,
a prior parameter pair in $\PkZ$ that minimizes system reliability, and
a prior parameter pair in $\PkZ$ that maximizes system reliability,
independently of the other component types. 
%such that system reliability is
%minimized by a distribution that gives most weight to low values of $l_k$, and
%maximized by a distribution that gives most weight to high values of $l_k$.
Indeed, stochastic dominance in $F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$ is provided for $\ykz$.
To see this, note that $\ykz$ gives the mean expected lifetime for type $k$ components.
Thus, higher values for $\ykz$ mean higher expected lifetimes for the components,
which in turn increases the probability that many components survive until time $t$,
and with it, decreases the propability of few or no components surviving,
so in total giving low probability weight for low values of $l_k$,
and high probability weight for high values of $l_k$. 
We therefore conclude that, for any fixed value of $\nkz$,
the lower bound of $F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$ for all $l_k$ is obtained with $\ykzu$, and
the upper bound of $F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$ for all $l_k$ is obtained with $\ykzl$.

***need formal first-order stochastic dominance in $\ykz$ result for $P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})$?
I have it for inverse gamma posterior $f(\lambda_k\mid \nkz,\ykz, \vec{t}^k_{e_k;n_k})$,
but not for posterior predictive***

However, there is no corresponding reasoning for $\nkz$,
such that different values of $\nkz$ may minimize (or maximize) $F(l_k \mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$ at different $l_k$'s.
Therefore, the $\nkz$ values for lower and upper system reliability bounds are obtained by numeric optimization.
%
\iffalse %---------------------------
\begin{linenomath*}
\begin{align} \label{eq:25}
\lefteqn{%
P(\Tsys > t\mid\{\nkz,\ykz, \mbf{t}^k_{e_k;n_k}\}_{k=1}^K)} \hspace*{10ex}\nonumber\\ 
 &= \sum_{l_1=0}^{n_1-e_1} \cdots \sum_{l_K=0}^{n_K-e_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K
    P(C^k_t = l_k\mid\nkz,\ykz, \vec{t}^k_{e_k;n_k})
\end{align}
\end{linenomath*}
we cannot simply plug in all the $\ul{P}(C^k_t = l_k\mid \ldots)$ %and $\ol{P}(C^k_t = l_k\mid \ldots)$
to get $\ul{P}(\Tsys > t\mid\nkz,\ykz, \mbf{t}^k_{e_k;n_k})$, % and $\ol{P}(\Tsys > t\mid\nkz,\ykz, \mbf{t}^k_{e_k;n_k})$,
as the $\ul{P}(C^k_t = l_k\mid \ldots)$ could correspond to different $(\nkz,\ykz)$ for each $l_k$.
(It would give us a lower bound for $\ul{P}(\Tsys > t\mid\ldots)$, however, but it might be very coarse.)
%
While it is clear that the lower bounds for $\ykz$ will lead to the lower system survival function,
the role of $\nkz$ is not so clear.
We therefore resort to numerical optimization of \eqref{eq:25} over $\{\nkz, k=1,\ldots,K\}$
to obtain the lower bound for $P(\Tsys > t\mid\{\nkz,\ykz, \mbf{t}^k_{e_k;n_k}\}_{k=1}^K)$.
\fi %---------------------------

Writing out \eqref{eq:sysrel-survsign}, we get
\begin{linenomath*}
\begin{align}
\lRsys(t \mid t > \tnow)
 &= \min_{\PZi{1},\ldots,\PZi{K}} \Rsys\big(t \mid t > \tnow, \cup_{k=1}^K \{\PkZ, \vec{t}^k_{e_k;n_k}\}\big) \nonumber\\
 &= \min_{\substack{\nkzfun{1} \in \left[\nkzlfun{1}, \nkzufun{1}\right]\\ \vdots\\ \nkzfun{K} \in \left[\nkzlfun{K}, \nkzufun{K}\right]}}
    \sum_{l_1=0}^{n_1-e_1} \cdots \sum_{l_K=0}^{n_K-e_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K P(C^k_t = l_k\mid\nkz,\ykzl, \mbf{t}^k_{e_k;n_k})\,,
\end{align}
\end{linenomath*}
such that a $K$-dimensional box-constraint optimization is needed to obtain $\lRsys(t \mid t > \tnow)$.
The result for $\uRsys(t \mid t > \tnow)$ is completely analogous.
Computing time can furthermore be saved
by computing only those $P(C^k_t = l_k\mid \nkz,\ykz,\vec{t}^k_{e_k;n_k})$ for $l_k$'s for which $\Phi(l_1,\ldots,l_K) > 0$.

\iffalse %---------------------------
\begin{linenomath*}
\begin{align}
\lefteqn{P(\Tsys > t\mid\{\nkz,\ykz, \mbf{t}^k_{e_k;n_k}\}_{k=1}^K)} \\
 &= \sum_{l_1=0}^{n_1-e_1} \cdots \sum_{l_K=0}^{n_K-e_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K
    P(C^k_t = l_k\mid\nkz,\ykz, \mbf{t}^k_{e_k;n_k}) \\
 &= \sum_{l_1=0}^{n_1-e_1} \cdots \sum_{l_K=0}^{n_K-e_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K
    \sum_{j=0}^{n_k-e_k-l_k} (-1)^j \frac{(n_k - e_k)!}{l_k! j! (n_k - e_k - l_k - j)!} \times \\ & \hspace*{45ex}
    \left(\frac{\nkn\ykn}{\nkn\ykn + (l_k + j) (t^\kappa - (\tnow)^\kappa)}\right)^{\nkn + 1} \\
 &= \sum_{l_1=0}^{n_1-e_1} \cdots \sum_{l_K=0}^{n_K-e_K} \Phi(l_1,\ldots,l_K) \prod_{k=1}^K \label{eq:30}
    \sum_{j=0}^{n_k-e_k-l_k} (-1)^j \frac{(n_k - e_k)!}{l_k! j! (n_k - e_k - l_k - j)!} \times \\ & \hspace*{17ex}
    \left(\frac{\nkz\ykz + \sum_{i=1}^{e_k} (t_i^k)^\kappa + (n_k-e_k) (\tnow)^\kappa }%
               {\nkz\ykz + \sum_{i=1}^{e_k} (t_i^k)^\kappa + (n_k-e_k-l_k-j) (\tnow)^\kappa + (l_k + j) t^\kappa }\right)^{%
    \nkz + e_k + 1} 
\end{align}
\end{linenomath*}
\fi %---------------------------


\section{Elicitation of prior parameter sets}

*** prior via pseudo-observations, can contain censored pseudo-data 

*** cf paper from Frank \cite{1996:coolen::cens}

\section{Examples}

***from poster, bridge type system Fig.~\ref{fig:bridge-layout}, or brake system from ijar paper?

we use box-constraint optimization with option \texttt{L-BFGS-B} of \texttt{optim} in \textsf{R}.


\begin{figure}
\centering
\begin{tikzpicture}
[type1/.style={rectangle,draw,fill=black!20,very thick,inner sep=0pt,minimum size=8mm},
 type2/.style={rectangle,draw,fill=black!20,very thick,inner sep=0pt,minimum size=8mm},
 type3/.style={rectangle,draw,fill=black!20,very thick,inner sep=0pt,minimum size=8mm},
 cross/.style={cross out,draw=red,very thick,minimum width=7mm, minimum height=5mm},
 hv path/.style={thick, to path={-| (\tikztotarget)}},
 vh path/.style={thick, to path={|- (\tikztotarget)}}]
%\begin{scope}[scale=0.75]
\node[type1] (T3)   at ( 5.6, 0) {T3};
\node[type2] (T2)   at ( 2.8, 0) {T2};
\node[type3] (T1-2) at ( 1.4, 1) {T1};
\node[type3] (T1-3) at ( 1.4,-1) {T1};
\node[type3] (T1-5) at ( 4.2, 1) {T1};
\node[type3] (T1-6) at ( 4.2,-1) {T1};
\coordinate (start) at (0  ,0);
\coordinate (end)   at (6.3,0);
\coordinate (bista) at (0.7,0);
\coordinate (biend) at (4.9,0);
\path (bista)     edge[hv path] (start)
                  edge[vh path] (T1-2.west)
                  edge[vh path] (T1-3.west)
      (T1-2.east) edge[hv path] (T2.north)
      (T1-3.east) edge[hv path] (T2.south)
      (T2.north)  edge[vh path] (T1-5.west)
      (T2.south)  edge[vh path] (T1-6.west)
      (biend)     edge[vh path] (T1-5.east)
                  edge[vh path] (T1-6.east)
                  edge[hv path] (T3.west)
      (T3.east)   edge[hv path] (end);
%\end{scope}
\end{tikzpicture}
\caption{Reliability block diagram for a `bridge' system with three component types.}
\label{fig:bridge-layout}
\end{figure}


\section{Concluding Remarks}


\pagebreak
%
%
% Now we start the appendices, with the new section name, "Appendix", and a 
%  new counter, "I", "II", etc.
%
\appendix\label{section:references}
%
% Here's the first appendix, the list of references:
%
\bibliography{refs}
%
%\cite{key}   produces citations with full author list and year 
%\citeNP{key} produces citations with full author list and year, but without enclosing parentheses
%\citeA{key}  produces citations with only the full author list
%\citeN{key}  produces citations with the full author list and year, but
%             which can be used as nouns in a sentence; no parentheses appear around
%             the author names, but only around the year
%\citeyear{key}   produces the year information only, within parentheses
%\citeyearNP{key} produces the year information only
%
%
% And now for some pretty impressive notation.  In this example, I have used
%   the tabular environment to line up the columns in ASCE style.
%   Note that this and all appendices (except the references) start with 
%   the \section command
%
\iffalse
\section{Notation}
\emph{The following symbols are used in this paper:}%\par\vspace{0.10in}
\nopagebreak
\par
\begin{tabular}{r  @{\hspace{1em}=\hspace{1em}}  l}
$D$                    & pile diameter (m); \\
$R$                    & distance (m);      and\\
$C_{\mathrm{Oh\;no!}}$ & fudge factor.
\end{tabular}
\fi

\end{document}
